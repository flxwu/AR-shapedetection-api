<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8" />
	<title>DevTalksSnapchat</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
	<div id="wrapper">
		<video id="videostream" preload autoplay loop muted></video>
		<canvas id="canvas" width="640" height="480"></canvas>
	</div>
</body>

<style>
	body {
		width: 100vw;
		height: 100vh;
		margin: 0;
	}
	#wrapper {
		position: relative;
		width: 100%;
		height: 100%;
	}
	#videostream {
		/* -webkit-filter: sepia(1);  */
	}
	#canvas {
		position: absolute;
		z-index: 2;
		top: 0;
		left: 0;
	}
</style>

<script>
	if (!navigator.mediaDevices.getUserMedia) {
		alert('Haha, you don\'t have a webcam ðŸ˜„');
	}

	if (typeof window.FaceDetector === 'undefined') {
		alert('You\'re either not using Chrome ðŸŒ, or haven\'t enabled the experimental-features flag! âš ï¸');
	}

	// get video tag to display webcam in
	const video = document.querySelector('#videostream');
	// get canvas and context to draw image on
	const canvas = document.querySelector('#canvas');
	canvas.style.height = video.offsetHeight;
	canvas.style.width = video.offsetWidth;
	const context = canvas.getContext('2d');

	// Initialize FaceDetector
	const faceDetector = new FaceDetector();
	const img = new Image();
	img.src = 'filter.png';

	navigator.mediaDevices.getUserMedia({ audio: false, video: true})
		.then(stream => {
			video.srcObject = stream;

			setInterval(() => {
				faceDetector.detect(video)
				.then(detectedFaces => {
					context.clearRect(0,0, canvas.width, canvas.height);
					for (let face of detectedFaces) {
						let { x, y, width, height } = face.boundingBox;

						context.drawImage(img, x, y - height * 0.75, width * 1.25, height);
					}
				}).catch(err => console.log(err));
			},250);
		})
</script>

</html>